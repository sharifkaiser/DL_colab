{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "tflite_rock_paper_scissors.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sharifkaiser/DL_colab/blob/master/tflite_rock_paper_scissors.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Za8-Nr5k11fh"
      },
      "source": [
        "##### Copyright 2018 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "Eq10uEbw0E4l"
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYM61xrTsP5d"
      },
      "source": [
        "# Rock, Paper & Scissors with TensorFlow Hub - TFLite"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAI9358VyAsE"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_lite/tflite_c05_exercise_rock_paper_scissors.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />\n",
        "    Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_lite/tflite_c05_exercise_rock_paper_scissors.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />\n",
        "    View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bL54LWCHt5q5"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "110fGB18UNJn"
      },
      "source": [
        "try:\n",
        "  %tensorflow_version 2.x\n",
        "except:\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlauq-4FWGZM"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import os\n",
        "\n",
        "import matplotlib.pylab as plt\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "print(\"Version: \", tf.__version__)\n",
        "print(\"Eager mode: \", tf.executing_eagerly())\n",
        "print(\"Hub version: \", hub.__version__)\n",
        "print(\"GPU is\", \"available\" if tf.test.is_gpu_available() else \"NOT AVAILABLE\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmaHHH7Pvmth"
      },
      "source": [
        "## Select the Hub/TF2 module to use\n",
        "\n",
        "Hub modules for TF 1.x won't work here, please use one of the selections provided."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlsEcKVeuCnf"
      },
      "source": [
        "# code in this block is for initializing all reqd data \n",
        "# for the hub module that we want to use\n",
        "# all values here are hard coded\n",
        "# all we need to do is to find the link of the module that we want to use\n",
        "# and find necessary info e.g. module name, input and output info from the link webpage\n",
        "\n",
        "# How to find the link? Go to tfhub webpage, filter by necessary info\n",
        "# and find the version that you want to use\n",
        "\n",
        "# as we are using transfer learning for training our model, we have to use feature vector\n",
        "\n",
        "module_selection = (\"mobilenet_v2\", 224, 1280)  # we use mobilenet_v2, the hard coded values are given in the link page\n",
        "module_name, pixels, OUTPUT_SHAPE = module_selection\n",
        "MODULE_URL =\"https://tfhub.dev/google/tf2-preview/{}/feature_vector/4\".format(module_name)\n",
        "IMAGE_SIZE = (pixels, pixels)\n",
        "print(\"Using {} with \\ninput size {} and \\noutput dimension {}\".format(\n",
        "  MODULE_URL, IMAGE_SIZE, OUTPUT_SHAPE))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYUsgwCBv87A"
      },
      "source": [
        "## Data preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nqVX3KYwGPh"
      },
      "source": [
        "Use [TensorFlow Datasets](http://tensorflow.org/datasets) to load the cats and dogs dataset.\n",
        "\n",
        "This `tfds` package is the easiest way to load pre-defined data. If you have your own data, and are interested in importing using it with TensorFlow see [loading image data](../load_data/images.ipynb)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGvpkDj4wBup"
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "tfds.disable_progress_bar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkF4Boe5wN7N"
      },
      "source": [
        "The `tfds.load` method downloads and caches the data, and returns a `tf.data.Dataset` object. These objects provide powerful, efficient methods for manipulating data and piping it into your model.\n",
        "\n",
        "Since `\"cats_vs_dog\"` doesn't define standard splits, use the subsplit feature to divide it into (train, validation, test) with 80%, 10%, 10% of the data respectively."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQ9xK9F2wGD8"
      },
      "source": [
        "splits = tfds.Split.ALL.subsplit(weighted=(80, 10, 10))\n",
        "\n",
        "# Go to the TensorFlow Dataset's website and search for the Rock, Paper, Scissors dataset and load it here\n",
        "splits, info = tfds.load(name='rock_paper_scissors', split=splits, with_info=True, as_supervised=True)\n",
        "    \n",
        "# Save the dataset splits in a tuple\n",
        "(train_examples, validation_examples, test_examples) = splits\n",
        "\n",
        "num_examples = info.splits['train'].num_examples\n",
        "num_classes = info.features['label'].num_classes\n",
        "\n",
        "# for this dataset image size is 300, but we are using mobilenet for which \n",
        "#  image size is 224, which we hard coded in selecting the hub code module"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmXQYXNWwf19"
      },
      "source": [
        "### Format the Data\n",
        "\n",
        "Use the `tf.image` module to format the images for the task.\n",
        "\n",
        "Resize the images to a fixes input size, and rescale the input channels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7UyXblSwkUS"
      },
      "source": [
        "def format_image(image, label):\n",
        "  # IMAGE_SIZE is actually defined as (pixel,pixel) already\n",
        "  # notice that resize does not care about third dimension which is color RGB\n",
        "  image = tf.image.resize(image, IMAGE_SIZE)/255.0\n",
        "  return  image, label\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nrDR8CnwrVk"
      },
      "source": [
        "Now shuffle and batch the data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAEUG7vawxLm"
      },
      "source": [
        "BATCH_SIZE = 32 #@param {type:\"integer\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHEC9mbswxvM"
      },
      "source": [
        "# Prepare the examples by preprocessing the them and then batching them (and optionally prefetching them)\n",
        "\n",
        "# If you wish you can shuffle train set here\n",
        "train_batches = train_examples.shuffle(num_examples // 4).batch(BATCH_SIZE).map(format_image).prefetch(1)\n",
        "validation_batches = validation_examples.batch(BATCH_SIZE).map(format_image).prefetch(1)\n",
        "# prefetch is not needed for test batches\n",
        "test_batches = test_examples.batch(1).map(format_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghQhZjgEw1cK"
      },
      "source": [
        "Inspect a batch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gz0xsMCjwx54"
      },
      "source": [
        "for image_batch, label_batch in train_batches.take(1):\n",
        "  pass\n",
        "\n",
        "image_batch.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FS_gVStowW3G"
      },
      "source": [
        "\n",
        "## Defining the model\n",
        "\n",
        "All it takes is to put a linear classifier on top of the `feature_extractor_layer` with the Hub module.\n",
        "\n",
        "For speed, we start out with a non-trainable `feature_extractor_layer`, but you can also enable fine-tuning for greater accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaJW3XrPyFiF"
      },
      "source": [
        "do_fine_tuning = False #@param {type:\"boolean\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50FYNIb1dmJH"
      },
      "source": [
        "# Build the model with a TFHub KerasLayer and attach a classification head to it\n",
        "print(\"Building model with\", MODULE_URL)\n",
        "# following line is important to understand\n",
        "# IMAGE_SIZE is a tuple: (224,224), we can only concat another tuple to it\n",
        "# our new tuple to concat is (3, ) i.e. 2nd tuple element does not exist\n",
        "INPUT_SHAPE = IMAGE_SIZE + (3, )  # height, width, dimension (3=RGB)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    hub.KerasLayer(MODULE_URL,\n",
        "                   input_shape=INPUT_SHAPE, \n",
        "                   output_shape=[OUTPUT_SHAPE],\n",
        "                   trainable=False),  # do not do fine tuning on tx learning\n",
        "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2e5WupIw2N2"
      },
      "source": [
        "## Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9f3yBUvkd_VJ"
      },
      "source": [
        "if do_fine_tuning:\n",
        "  model.compile(\n",
        "    optimizer=tf.keras.optimizers.SGD(lr=0.002, momentum=0.9), \n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics=['accuracy'])\n",
        "else:\n",
        "  model.compile(\n",
        "    optimizer='adam', \n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_YKX2Qnfg6x"
      },
      "source": [
        "EPOCHS = 3\n",
        "hist = model.fit(train_batches,\n",
        "                    epochs=EPOCHS,\n",
        "                    validation_data=validation_batches)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_psFoTeLpHU"
      },
      "source": [
        "## Export the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaSb5nVzHcVv"
      },
      "source": [
        "RPS_SAVED_MODEL = \"exp_saved_model\" # export directory for saving"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZqRAg1uz1Nu"
      },
      "source": [
        "Export the SavedModel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJMue5YgnwtN"
      },
      "source": [
        "# saves the model to RPS_SAVED_MODEL directory as .pb file \n",
        "tf.saved_model.save(model, RPS_SAVED_MODEL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVrnAWjqCMxs"
      },
      "source": [
        "Here you can verify the default signature of your exported SavedModel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOQF4cOan0SY"
      },
      "source": [
        "%%bash -s $RPS_SAVED_MODEL\n",
        "saved_model_cli show --dir $1 --tag_set serve --signature_def serving_default"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FY7QGBgBytwX"
      },
      "source": [
        "loaded = tf.saved_model.load(RPS_SAVED_MODEL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIhPyMISz952"
      },
      "source": [
        "print(list(loaded.signatures.keys()))\n",
        "infer = loaded.signatures[\"serving_default\"]\n",
        "print(infer.structured_input_signature)\n",
        "print(infer.structured_outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxLiLC8n0H16"
      },
      "source": [
        "## Convert with TFLiteConverter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmSr2-yZoUhz"
      },
      "source": [
        "# Intialize the TFLite converter to load the SavedModel\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(RPS_SAVED_MODEL)\n",
        "# Set the optimization strategy for 'size' in the converter \n",
        "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
        "\n",
        "# Use the tool to finally convert the model\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# following, opening a file with name converted_model.tflite and writing in it\n",
        "with open(\"converted_model.tflite\", \"wb\") as f:\n",
        "  f.write(tflite_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbTF6nd1KG2o"
      },
      "source": [
        "Run the following cells to check whether your TFLite model is working using the Python Interpreter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "id": "dg2NkVTmLUdJ"
      },
      "source": [
        "# Loading the converted TFLite model...\n",
        "# Load TFLite model and allocate tensors.\n",
        "tflite_model_file = 'converted_model.tflite'\n",
        "with open(tflite_model_file, 'rb') as fid:  # open as read-only binary\n",
        "  tflite_model = fid.read()\n",
        "  \n",
        "# sequence of these calls are very important\n",
        "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "output_index = interpreter.get_output_details()[0][\"index\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "id": "snJQVs9JNglv"
      },
      "source": [
        "# Testing on random test examples...\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Gather results for the randomly sampled test images\n",
        "predictions = []\n",
        "\n",
        "test_labels, test_imgs = [], []\n",
        "for img, label in tqdm(test_batches.take(10)):\n",
        "  interpreter.set_tensor(input_index, img)\n",
        "  interpreter.invoke()\n",
        "  predictions.append(interpreter.get_tensor(output_index))\n",
        "  \n",
        "  test_labels.append(label.numpy()[0])\n",
        "  test_imgs.append(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "id": "YMTWNqPpNiAI"
      },
      "source": [
        "# Utilities for plotting\n",
        "\n",
        "class_names = ['rock', 'paper', 'scissors']\n",
        "\n",
        "def plot_image(i, predictions_array, true_label, img):\n",
        "  predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]\n",
        "  plt.grid(False)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "    \n",
        "  img = np.squeeze(img)\n",
        "\n",
        "  plt.imshow(img, cmap=plt.cm.binary)\n",
        "\n",
        "  predicted_label = np.argmax(predictions_array)\n",
        "  if predicted_label == true_label:\n",
        "    color = 'green'\n",
        "  else:\n",
        "    color = 'red'\n",
        "  \n",
        "  plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
        "                                100*np.max(predictions_array),\n",
        "                                class_names[true_label]),\n",
        "                                color=color)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "1-lbnicPNkZs"
      },
      "source": [
        "#@title Visualize the outputs { run: \"auto\" }\n",
        "index = 0 #@param {type:\"slider\", min:0, max:9, step:1}\n",
        "plt.figure(figsize=(6,3))\n",
        "plt.subplot(1,2,1)\n",
        "plot_image(index, predictions, test_labels, test_imgs)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmZRieHmKLY5"
      },
      "source": [
        "Download the model\n",
        "\n",
        "**NOTE: You might have to run to the cell below twice**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jJAxrQB2VFw"
      },
      "source": [
        "with open('labels.txt', 'w') as f:\n",
        "  f.write('\\n'.join(class_names))\n",
        "\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "  files.download('converted_model.tflite')  \n",
        "  files.download('labels.txt')\n",
        "except:\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDlmpjC6VnFZ"
      },
      "source": [
        "# Prepare the test images for download (Optional)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1ja_WA0WZOH"
      },
      "source": [
        "This part involves downloading additional test images for the Mobile Apps only in case you need to try out more samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzLKEBrfTREA"
      },
      "source": [
        "!mkdir -p test_images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qn7ukNQCSewb"
      },
      "source": [
        "from PIL import Image\n",
        "\n",
        "for index, (image, label) in enumerate(test_batches.take(50)):\n",
        "  image = tf.cast(image * 255.0, tf.uint8)\n",
        "  image = tf.squeeze(image).numpy()\n",
        "  pil_image = Image.fromarray(image)\n",
        "  pil_image.save('test_images/{}_{}.jpg'.format(class_names[label[0]], index))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVKKWUG8UMO5"
      },
      "source": [
        "!ls test_images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_w_-UdlS9Vi"
      },
      "source": [
        "!zip -qq rps_test_images.zip -r test_images/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Giva6EHwWm6Y"
      },
      "source": [
        "try:\n",
        "  files.download('rps_test_images.zip')\n",
        "except:\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}